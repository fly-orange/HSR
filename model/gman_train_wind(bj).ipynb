{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:51:52.243149Z",
     "start_time": "2021-07-18T03:51:52.233923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchsummary import *\n",
    "from gman import *\n",
    "import time\n",
    "import datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:51:58.431775Z",
     "start_time": "2021-07-18T03:51:58.402885Z"
    }
   },
   "outputs": [],
   "source": [
    "# log string\n",
    "def log_string(log, string):\n",
    "    log.write(string + '\\n')\n",
    "    log.flush()\n",
    "    print(string)\n",
    "# metric\n",
    "def metric(pred, label):\n",
    "    mask = torch.ne(label, 0)\n",
    "    mask = mask.type(torch.float32)\n",
    "    mask /= torch.mean(mask)\n",
    "    mae = torch.abs(torch.sub(pred, label)).type(torch.float32)\n",
    "    rmse = mae ** 2\n",
    "    mape = mae / label\n",
    "    mae = torch.mean(mae)\n",
    "    rmse = rmse * mask\n",
    "    rmse = torch.sqrt(torch.mean(rmse))\n",
    "    mape = mape * mask\n",
    "    mape = torch.mean(mape)\n",
    "    return mae, rmse, mape\n",
    "\n",
    "def seq2instance(data, P, Q):\n",
    "    num_step, dims = data.shape\n",
    "    num_sample = num_step - P - Q + 1\n",
    "    x = torch.zeros(num_sample, P, dims)\n",
    "    y = torch.zeros(num_sample, Q, dims)\n",
    "    for i in range(num_sample):\n",
    "        x[i] = data[i : i + P]\n",
    "        y[i] = data[i + P : i + P + Q]\n",
    "    return x, y\n",
    "\n",
    "def loadData(data_args):\n",
    "    # Traffic\n",
    "    df = pd.read_csv(data_args['data_file'],index_col=0)\n",
    "    Traffic = torch.from_numpy(df.values)\n",
    "    # train/val/test \n",
    "    num_step = df.shape[0]\n",
    "    train_steps = round(data_args['train_ratio'] * num_step)\n",
    "    test_steps = round(data_args['test_ratio'] * num_step)\n",
    "    val_steps = num_step - train_steps - test_steps\n",
    "    train = Traffic[: train_steps]\n",
    "    val = Traffic[train_steps : train_steps + val_steps]\n",
    "    test = Traffic[-test_steps :]\n",
    "    # X, Y \n",
    "    trainX, trainY = seq2instance(train, data_args['P'], data_args['Q'])\n",
    "    valX, valY = seq2instance(val,data_args['P'], data_args['Q'])\n",
    "    testX, testY = seq2instance(test,data_args['P'], data_args['Q'])\n",
    "    # normalization\n",
    "    mean, std = torch.mean(trainX), torch.std(trainX)\n",
    "    trainX = (trainX - mean) / std\n",
    "    valX = (valX - mean) / std\n",
    "    testX = (testX - mean) / std\n",
    "    \n",
    "    # temporal embedding \n",
    "    time = pd.DatetimeIndex(df.index)\n",
    "    dayofweek = torch.reshape(torch.tensor(time.weekday), (-1, 1))\n",
    "#     timeofday = (time.hour * 3600 + time.minute * 60 + time.second) \\\n",
    "#                 // time.freq.delta.total_seconds()\n",
    "#     timeofday = torch.reshape(torch.tensor(timeofday), (-1, 1))\n",
    "    timeofday = (time.values - df.index.values.astype(\"datetime64[D]\")) / np.timedelta64(1, \"D\")\n",
    "    timeofday = torch.reshape(torch.tensor(timeofday), (-1, 1))        \n",
    "    time = torch.cat((dayofweek, timeofday), -1)\n",
    "    # train/val/test\n",
    "    train = time[: train_steps]\n",
    "    val = time[train_steps : train_steps + val_steps]\n",
    "    test = time[-test_steps :]\n",
    "    # shape = (num_sample, P + Q, 2)\n",
    "    trainTE = seq2instance(train,data_args['P'], data_args['Q'])\n",
    "    trainTE = torch.cat(trainTE, 1).type(torch.int32)\n",
    "    valTE = seq2instance(val, data_args['P'], data_args['Q'])\n",
    "    valTE = torch.cat(valTE, 1).type(torch.int32)\n",
    "    testTE = seq2instance(test, data_args['P'],data_args['Q'])\n",
    "    testTE = torch.cat(testTE, 1).type(torch.int32)\n",
    "    \n",
    "    return (trainX, trainTE, trainY, valX, valTE, valY, testX, testTE, testY,\n",
    "             mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:55:47.327505Z",
     "start_time": "2021-07-18T03:55:46.014547Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_args={\n",
    "'data_file' : '../Wind/tj_wind_10m.csv',\n",
    "# 'SE_file' : './Dataset/PEMS-BAY/SE(PeMS).txt',\n",
    "'train_ratio' : 0.7,\n",
    "'test_ratio' : 0.1,\n",
    "'P' : 32,\n",
    "'Q' : 8,\n",
    "}\n",
    "(trainX, trainTE, trainY, valX, valTE, valY, testX, testTE, testY,\n",
    " mean, std) = loadData(data_args)\n",
    "SE = torch.zeros((12,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T11:59:57.251291Z",
     "start_time": "2021-07-17T11:59:57.249418Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adj = pd.read_csv('./Dataset/PEMS-BAY/Adj(PeMS).txt',header =None)\n",
    "# adj = adj.iloc[:,0].apply(lambda x: x.split(' ')[-1])\n",
    "# adj = np.array(list(map(float,adj.values))).reshape((325,325))\n",
    "# adj = torch.from_numpy(adj)\n",
    "# adj = adj [0:,0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:54:49.989315Z",
     "start_time": "2021-07-18T03:54:49.913267Z"
    }
   },
   "outputs": [],
   "source": [
    "nnodes = 30\n",
    "ne = 3\n",
    "ndim = 32\n",
    "alpha = 0.5\n",
    "L = 3\n",
    "K = 8\n",
    "d = 8\n",
    "num_his = data_args['P']\n",
    "num_pred = data_args['Q']\n",
    "bn_decay =0.1\n",
    "steps_per_day = 288\n",
    "use_bias = False\n",
    "mask = True\n",
    "model = GMAN(L,K,d,num_his,bn_decay,steps_per_day,use_bias,mask,SE,device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T12:00:00.510808Z",
     "start_time": "2021-07-17T12:00:00.507857Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from torchsummary import *\n",
    "# summary(model,input_size=[(12,325),(15,2)],batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:55:50.162717Z",
     "start_time": "2021-07-18T03:55:50.143672Z"
    }
   },
   "outputs": [],
   "source": [
    "max_epochs =100\n",
    "patience =7\n",
    "batch_size = 64\n",
    "LR = 0.01\n",
    "decay_epoch = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                      step_size=decay_epoch,\n",
    "                                      gamma=0.9)\n",
    "loss_criterion = nn.L1Loss().to(device)\n",
    "model_file = '../result/model/gman_tj10_32-8.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:55:03.843856Z",
     "start_time": "2021-07-18T03:54:56.549989Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** training model ****\n",
      "Training batch: 5 in epoch:0, training batch loss:0.9184\n",
      "Training batch: 10 in epoch:0, training batch loss:0.9113\n",
      "Training batch: 15 in epoch:0, training batch loss:0.9126\n",
      "Training batch: 20 in epoch:0, training batch loss:0.9165\n",
      "Training batch: 25 in epoch:0, training batch loss:0.8580\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-85c6996ee133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training batch: {batch_idx+1} in epoch:{epoch}, training batch loss:{loss_batch:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/lc/lib/python3.6/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_file = '../Wind/log(bjWind)'\n",
    "log = open(log_file, 'w')\n",
    "log_string(log, '**** training model ****')\n",
    "num_val = valX.shape[0]\n",
    "num_train = trainX.shape[0]\n",
    "# num_train = 800\n",
    "num_test = testX.shape[0]\n",
    "train_num_batch = math.ceil(num_train / batch_size)\n",
    "val_num_batch = math.ceil(num_val / batch_size)\n",
    "test_num_batch = math.ceil(num_test / batch_size)\n",
    "wait = 0\n",
    "val_loss_min = float('inf')\n",
    "best_model_wts = None\n",
    "train_total_loss = []\n",
    "val_total_loss = []\n",
    "# shuffle\n",
    "SE = SE.to(device)\n",
    "# model = torch.load(model_file)\n",
    "for epoch in range(max_epochs):    \n",
    "    if wait >= patience:\n",
    "        log_string(log, f'early stop at epoch: {epoch:04d}')\n",
    "        break\n",
    "    permutation = torch.randperm(num_train)\n",
    "    trainX = trainX[permutation]\n",
    "    trainTE = trainTE[permutation]\n",
    "    trainY = trainY[permutation]\n",
    "    # train\n",
    "    start_train = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx in range(train_num_batch):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(num_train, (batch_idx + 1) * batch_size)\n",
    "        X = trainX[start_idx: end_idx].to(device)\n",
    "        TE = trainTE[start_idx: end_idx].to(device)\n",
    "        label = trainY[start_idx: end_idx].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X, TE)\n",
    "        pred = pred * std + mean\n",
    "        loss_batch = loss_criterion(pred, label)\n",
    "        train_loss += float(loss_batch) * (end_idx - start_idx)\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        if (batch_idx+1) % 5 == 0:\n",
    "            print(f'Training batch: {batch_idx+1} in epoch:{epoch}, training batch loss:{loss_batch:.4f}')\n",
    "        del X, TE, label, pred, loss_batch\n",
    "    train_loss /= num_train\n",
    "    train_total_loss.append(train_loss)\n",
    "    end_train = time.time()\n",
    "\n",
    "    # val loss\n",
    "    start_val = time.time()\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(val_num_batch):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min(num_val, (batch_idx + 1) * batch_size)\n",
    "            X = valX[start_idx: end_idx].to(device)\n",
    "            TE = valTE[start_idx: end_idx].to(device)\n",
    "            label = valY[start_idx: end_idx].to(device)\n",
    "            pred = model(X, TE)\n",
    "            pred = pred * std + mean\n",
    "            loss_batch = loss_criterion(pred, label)\n",
    "            val_loss += loss_batch * (end_idx - start_idx)\n",
    "            del X, TE, label, pred, loss_batch\n",
    "    val_loss /= num_val\n",
    "    val_total_loss.append(val_loss)\n",
    "    end_val = time.time()\n",
    "    log_string(\n",
    "        log,\n",
    "        '%s | epoch: %04d/%d, training time: %.1fs, inference time: %.1fs' %\n",
    "        (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), epoch + 1,\n",
    "         max_epochs, end_train - start_train, end_val - start_val))\n",
    "    log_string(\n",
    "        log, f'train loss: {train_loss:.4f}, val_loss: {val_loss:.4f}')\n",
    "    if val_loss <= val_loss_min:\n",
    "        log_string(\n",
    "            log,\n",
    "            f'val loss decrease from {val_loss_min:.4f} to {val_loss:.4f}, saving model to {model_file}')\n",
    "        wait = 0\n",
    "        val_loss_min = val_loss\n",
    "        best_model_wts = model.state_dict()\n",
    "        torch.save(model, model_file)\n",
    "    else:\n",
    "        wait += 1\n",
    "    scheduler.step()\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model, model_file)\n",
    "log_string(log, f'Training and validation are completed, and model has been stored as {model_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T03:55:56.990227Z",
     "start_time": "2021-07-18T03:55:52.890717Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From step 0 to step 2\n",
      " Prediction performance:   MAE: 0.3964328467845917, RMSE: 0.5046855211257935, MAPE: 0.11491795629262924\n",
      "From step 2 to step 4\n",
      " Prediction performance:   MAE: 0.3468914031982422, RMSE: 0.4548645615577698, MAPE: 0.10042881220579147\n",
      "From step 4 to step 8\n",
      " Prediction performance:   MAE: 0.38741934299468994, RMSE: 0.5100828409194946, MAPE: 0.11252658814191818\n",
      "During all steps\n",
      " Prediction performance:   MAE: 0.37954074144363403, RMSE: 0.49547410011291504, MAPE: 0.11009998619556427\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'alarm_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-55be78c2b312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlog_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'During all steps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mlog_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf' Prediction performance:   MAE: {test_mae}, RMSE: {test_rmse}, MAPE: {test_mape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malarm_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestPred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mlog_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34mf' Alarm performance:   precision score: {precision}, recall score: {recall}, F1 score: {f1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alarm_metric' is not defined"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "model = torch.load(model_file)\n",
    "num_test = testX.shape[0]\n",
    "test_num_batch = math.ceil(num_test / batch_size)\n",
    "testPred = []\n",
    "start_test = time.time()\n",
    "for batch_idx in range(test_num_batch):\n",
    "    start_idx = batch_idx * batch_size\n",
    "    end_idx = min(num_test, (batch_idx + 1) * batch_size)\n",
    "    X = testX[start_idx: end_idx].to(device)\n",
    "    TE = testTE[start_idx: end_idx].to(device)\n",
    "    pred_batch = model(X, TE)\n",
    "    testPred.append(pred_batch.detach().clone())\n",
    "    del X, TE, pred_batch\n",
    "testPred = torch.cat(testPred, axis=0)\n",
    "testPred = testPred* std + mean\n",
    "max_length = int(math.log(data_args['Q'],2))\n",
    "for i in range(max_length):\n",
    "    if i!=0:\n",
    "        start_idx = pow(2,i)\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    end_idx = pow(2,i+1)\n",
    "    pred = testPred[:,start_idx:end_idx]\n",
    "    label = testY[:,start_idx:end_idx]\n",
    "    test_mae, test_rmse, test_mape = metric(pred, label.to(device))\n",
    "    log_string(log, f'From step {start_idx} to step {end_idx}')\n",
    "    log_string(log, f' Prediction performance:   MAE: {test_mae}, RMSE: {test_rmse}, MAPE: {test_mape}')\n",
    "test_mae, test_rmse, test_mape = metric(testPred, testY.to(device))\n",
    "log_string(log, 'During all steps')\n",
    "log_string(log, f' Prediction performance:   MAE: {test_mae}, RMSE: {test_rmse}, MAPE: {test_mape}')\n",
    "precision, recall, f1 = alarm_metric(testPred,testY,threshold)\n",
    "log_string(log,  f' Alarm performance:   precision score: {precision}, recall score: {recall}, F1 score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-17T08:01:27.639482Z",
     "start_time": "2021-07-17T08:01:27.634023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5217, 8, 12])\n"
     ]
    }
   ],
   "source": [
    "print(testPred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a8386ff1b1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlog_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'**** testing model ****'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlog_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loading model from %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log' is not defined"
     ]
    }
   ],
   "source": [
    "model= torch.load(model_file)\n",
    "num_train, _, num_vertex = trainX.shape\n",
    "num_val = valX.shape[0]\n",
    "num_test = testX.shape[0]\n",
    "train_num_batch = math.ceil(num_train / batch_size)\n",
    "val_num_batch = math.ceil(num_val / batch_size)\n",
    "test_num_batch = math.ceil(num_test / batch_size)\n",
    "\n",
    "# test model\n",
    "log_string(log, '**** testing model ****')\n",
    "log_string(log, 'loading model from %s' % model_file)\n",
    "model = torch.load(model_file)\n",
    "log_string(log, 'model restored!')\n",
    "log_string(log, 'evaluating...')\n",
    "\n",
    "with torch.no_grad():\n",
    "    trainPred = []\n",
    "    for batch_idx in range(train_num_batch):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(num_train, (batch_idx + 1) * batch_size)\n",
    "        X = trainX[start_idx: end_idx]\n",
    "        TE = trainTE[start_idx: end_idx]\n",
    "        pred_batch = model(X, TE)\n",
    "        trainPred.append(pred_batch.detach().clone())\n",
    "        del X, TE, pred_batch\n",
    "    trainPred = torch.from_numpy(np.concatenate(trainPred, axis=0))\n",
    "    trainPred = trainPred * std + mean\n",
    "\n",
    "    valPred = []\n",
    "    for batch_idx in range(val_num_batch):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(num_val, (batch_idx + 1) * batch_size)\n",
    "        X = valX[start_idx: end_idx]\n",
    "        TE = valTE[start_idx: end_idx]\n",
    "        pred_batch = model(X, TE)\n",
    "        valPred.append(pred_batch.detach().clone())\n",
    "        del X, TE, pred_batch\n",
    "    valPred = torch.from_numpy(np.concatenate(valPred, axis=0))\n",
    "    valPred = valPred * std + mean\n",
    "\n",
    "    testPred = []\n",
    "    start_test = time.time()\n",
    "    for batch_idx in range(test_num_batch):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(num_test, (batch_idx + 1) * batch_size)\n",
    "        X = testX[start_idx: end_idx]\n",
    "        TE = testTE[start_idx: end_idx]\n",
    "        pred_batch = model(X, TE)\n",
    "        testPred.append(pred_batch.detach().clone())\n",
    "        del X, TE, pred_batch\n",
    "    testPred = torch.from_numpy(np.concatenate(testPred, axis=0))\n",
    "    testPred = testPred* std + mean\n",
    "end_test = time.time()\n",
    "train_mae, train_rmse, train_mape = metric(trainPred, trainY)\n",
    "val_mae, val_rmse, val_mape = metric(valPred, valY)\n",
    "test_mae, test_rmse, test_mape = metric(testPred, testY)\n",
    "log_string(log, 'testing time: %.1fs' % (end_test - start_test))\n",
    "log_string(log, '                MAE\\t\\tRMSE\\t\\tMAPE')\n",
    "log_string(log, 'train            %.2f\\t\\t%.2f\\t\\t%.2f%%' %\n",
    "           (train_mae, train_rmse, train_mape * 100))\n",
    "log_string(log, 'val              %.2f\\t\\t%.2f\\t\\t%.2f%%' %\n",
    "           (val_mae, val_rmse, val_mape * 100))\n",
    "log_string(log, 'test             %.2f\\t\\t%.2f\\t\\t%.2f%%' %\n",
    "           (test_mae, test_rmse, test_mape * 100))\n",
    "log_string(log, 'performance in each prediction step')\n",
    "MAE, RMSE, MAPE = [], [], []\n",
    "for step in range(num_pred):\n",
    "    mae, rmse, mape = metric(testPred[:, step], testY[:, step])\n",
    "    MAE.append(mae)\n",
    "    RMSE.append(rmse)\n",
    "    MAPE.append(mape)\n",
    "    log_string(log, 'step: %02d         %.2f\\t\\t%.2f\\t\\t%.2f%%' %\n",
    "               (step + 1, mae, rmse, mape * 100))\n",
    "average_mae = np.mean(MAE)\n",
    "average_rmse = np.mean(RMSE)\n",
    "average_mape = np.mean(MAPE)\n",
    "log_string(\n",
    "    log, 'average:         %.2f\\t\\t%.2f\\t\\t%.2f%%' %\n",
    "         (average_mae, average_rmse, average_mape * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-lc]",
   "language": "python",
   "name": "conda-env-.conda-lc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
